#---- Synapse and AWS Service Endpoints
org.sagebionetworks.authenticationservice.publicendpoint=${org.sagebionetworks.authenticationservice.endpoint}
org.sagebionetworks.repositoryservice.endpoint=${org.sagebionetworks.repositoryservice.endpoint}
org.sagebionetworks.portal.endpoint=${org.sagebionetworks.portal.endpoint}
aws.swf.endpoint=https://flow.us-east-1.amazonaws.com
aws.sns.endpoint=https://sns.us-east-1.amazonaws.com

#---- SNS Topics
org.sagebionetworks.sns.topic.workflow=arn:aws:sns:us-east-1:325565585839:TestTCGACurationWorkflow

#---- Local Cache directory in which to store downloads
org.sagebionetworks.localCacheDir=./synapseCache

#--- The Synapse account used by this workflow
org.sagebionetworks.synapse.username=devUser1@sagebase.org
org.sagebionetworks.synapse.password=password
org.sagebionetworks.synapse.secretkey=yourSecretKey



org.sagebionetworks.rScript.path=Rscript

org.sagebionetoworks.gepipeline.crawlerscript=src/main/resources/datasetCrawler.R
org.sagebionetoworks.gepipeline.workflowscript=src/main/resources/runMetaGeoQC.R

## set to -1 to remove the limit ## 
org.sagebionetworks.gepipeline.maxworkflowinstances=-1

org.sagebionetworks.gepipeline.noop=false

# These variables define job sizes and machine capacities
# E.g. a job has size 'medium' if it can be accommodated
# by the defined 'medium' amount of memory but not the defined
# 'small' amount. (A 20GB job is 'medium').  A machine
# is 'medium' sized if it has at LEAST the 'medium' capacity.
org.sagebionetworks.gepipeline.smallGB=15
org.sagebionetworks.gepipeline.mediumGB=32
org.sagebionetworks.gepipeline.largeGB=64

